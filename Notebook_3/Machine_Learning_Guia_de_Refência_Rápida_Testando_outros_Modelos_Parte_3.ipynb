{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pergunta a ser respondida:\n",
        "\n",
        "- Classificar se um indivíduo sobreviveu ou morreu ao afundamento do Titanic.\n",
        "\n",
        "  - Temos uma pergunta de classificação, pois estamos fazendo a predição de um rótulo (label) acerca da sobrevivência: um passageiro sobreviveu ou morreu."
      ],
      "metadata": {
        "id": "xegu9hdELw8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dicionários dos atributos:\n",
        "\n",
        "- pclass: classe do passageiro (1=primeiroa, 2=segunda, 3=terceira);\n",
        "- survived: sobreviveu (0=não, 1=sim);\n",
        "- name: nome;\n",
        "- sex: sexo;\n",
        "- age: idade;\n",
        "- sibsp: número de irmãos/esposa(o) a bordo;\n",
        "- parch: número de pais/filhos a bordo;\n",
        "- ticket: número da passagem;\n",
        "- fare: preço da passagem;\n",
        "- cabin: cabine;\n",
        "- embarked: local em que o passageiro embarcou (C=Cherbourg, Q=Queenstown, S=Southampton);\n",
        "- boat: bote salva-vidas;\n",
        "- body: número de identificação do corpo;\n",
        "- home.dest: lar/destino;"
      ],
      "metadata": {
        "id": "4ymQL2SgL2RD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Refatoração do código"
      ],
      "metadata": {
        "id": "NORcUEYrL9eb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports necessários"
      ],
      "metadata": {
        "id": "KjfvBtnQML-Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_zzsYfUoLq1a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from yellowbrick.classifier import ConfusionMatrix\n",
        "from yellowbrick.classifier import ROCAUC\n",
        "from sklearn import (\n",
        "    ensemble,\n",
        "    preprocessing,\n",
        "    tree\n",
        ")\n",
        "from sklearn.metrics import (\n",
        "    auc,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        "    roc_curve\n",
        ")\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    StratifiedKFold\n",
        ")\n",
        "from yellowbrick.model_selection import (\n",
        "    LearningCurve\n",
        ")\n",
        "from sklearn.experimental import (enable_iterative_imputer)\n",
        "from sklearn import impute"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extração dos dados e formação do dataframe"
      ],
      "metadata": {
        "id": "jY6JBsCjMRGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"titanic3.csv\")"
      ],
      "metadata": {
        "id": "IxEVhzhLMXZy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funções:"
      ],
      "metadata": {
        "id": "6IknnpBSMeUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Limpeza dos dados"
      ],
      "metadata": {
        "id": "WeoyKxiWNT9u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- exclusão dos campos desnecessários;\n",
        "- transformação das variáveis dummies;"
      ],
      "metadata": {
        "id": "U3xQBzhlNJpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def limpeza_dados(df):\n",
        "  df = df.drop(\n",
        "            columns=[\n",
        "                      \"name\",\n",
        "                      \"ticket\",\n",
        "                      \"home.dest\",\n",
        "                      \"boat\",\n",
        "                      \"body\",\n",
        "                      \"cabin\"\n",
        "  ]).pipe(pd.get_dummies, drop_first=True) # O uso do pipe permite que essas operações sejam encadeadas de forma mais limpa e eficiente\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "0dJRglL_Mdzj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Divisão de dados para treino e teste e imputando dados ausentes"
      ],
      "metadata": {
        "id": "bglv7L_0NYk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_test_X_y(df, y_col, size=0.3, std_cols=None):\n",
        "  y = df[y_col]\n",
        "  X = df.drop(columns=y_col)\n",
        "  X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
        "                                                                      X, y, test_size=size, random_state=42\n",
        "                                                                    )\n",
        "  cols = X.columns\n",
        "  num_cols = [\n",
        "                \"pclass\",\n",
        "                \"age\",\n",
        "                \"sibsp\",\n",
        "                \"parch\",\n",
        "                \"fare\"\n",
        "              ]\n",
        "\n",
        "  fi = impute.IterativeImputer()\n",
        "  X_train.loc[:, num_cols] = fi.fit_transform(X_train[num_cols])\n",
        "  X_test.loc[:, num_cols] = fi.transform(X_test[num_cols])\n",
        "\n",
        "  if std_cols:\n",
        "    std = preprocessing.StandardScaler()\n",
        "    X_train.loc[:, std_cols] = std.fit_transform(X_train[std_cols])\n",
        "    X_test.loc[:, std_cols] = std.transform(X_test[std_cols])\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "#.loc[:, num_cols] - pega todas as linhas (:) e as coliunas indicadas na variável num_cols"
      ],
      "metadata": {
        "id": "R9GuCOiiNG6G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chamando as funções"
      ],
      "metadata": {
        "id": "VgxuhwSwPg2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ti_df = limpeza_dados(df)\n",
        "std_cols = \"pclass,age,sibsp,fare\".split(\",\")\n",
        "X_train, X_test, y_train, y_test = get_train_test_X_y(ti_df, \"survived\", std_cols=std_cols)"
      ],
      "metadata": {
        "id": "d6ei5tCEPgTZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo - teste 1"
      ],
      "metadata": {
        "id": "zk6JunIqR6OQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "bm = DummyClassifier()\n",
        "\n",
        "bm.fit(X_train, y_train)\n",
        "bm.score(X_test, y_test) # precisão"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Kyxh8zMSFBr",
        "outputId": "9832d192-5253-432e-d327-0c18406acb52"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5699745547073791"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vendo a métrica da precisão"
      ],
      "metadata": {
        "id": "oXbl4NrISVFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "metrics.precision_score(y_test, bm.predict(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2acuXx4SYMY",
        "outputId": "0ba53813-a92c-4f87-f430-755e5bbf4a84"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testando outros modelos para comparação"
      ],
      "metadata": {
        "id": "43X90aMsmbJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Objetivo: encontrar um modelo que tenha uma pontuação média um pouco menor e um desvio-padrão um pouco menor."
      ],
      "metadata": {
        "id": "UKjHY_hllp2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.concat([X_train, X_test])\n",
        "y = pd.concat([y_train, y_test])"
      ],
      "metadata": {
        "id": "vQOdtynKmekS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost"
      ],
      "metadata": {
        "id": "ShgibUsqmrQ8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in [\n",
        "                DummyClassifier,\n",
        "                LogisticRegression,\n",
        "                DecisionTreeClassifier,\n",
        "                KNeighborsClassifier,\n",
        "                GaussianNB,\n",
        "                SVC,\n",
        "                RandomForestClassifier,\n",
        "                xgboost.XGBClassifier\n",
        "                ]:\n",
        "  cls = model()\n",
        "  kfold = model_selection.KFold(n_splits=10, random_state=42, shuffle=True)\n",
        "  s = model_selection.cross_val_score(cls, X, y, scoring=\"roc_auc\", cv=kfold)\n",
        "  print (\n",
        "          f\"{model.__name__:22} AUC: \"\n",
        "          f\"{s.mean():.3f} STD: {s.std():.2f}\"\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_8dGDXJnYEO",
        "outputId": "54375e42-b30f-473c-a566-a3d90e53128c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DummyClassifier        AUC: 0.500 STD: 0.00\n",
            "LogisticRegression     AUC: 0.840 STD: 0.04\n",
            "DecisionTreeClassifier AUC: 0.768 STD: 0.02\n",
            "KNeighborsClassifier   AUC: 0.829 STD: 0.02\n",
            "GaussianNB             AUC: 0.811 STD: 0.05\n",
            "SVC                    AUC: 0.838 STD: 0.03\n",
            "RandomForestClassifier AUC: 0.849 STD: 0.02\n",
            "XGBClassifier          AUC: 0.853 STD: 0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definições:"
      ],
      "metadata": {
        "id": "sEoXOatQl1bb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Pontuação AUC**\n",
        "AUC (Area Under the Curve) é uma métrica comum usada para **avaliar a performance de modelos de classificação binária**.\n",
        "\n",
        "  - O que é AUC?\n",
        "\n",
        "Definição: A AUC mede a área sob a curva ROC (Receiver Operating Characteristic). A curva ROC é uma representação gráfica que mostra o desempenho de um modelo de classificação binária em diferentes thresholds de discriminação.\n",
        "\n",
        "**Valores: A AUC varia de 0 a 1**, onde:\n",
        "\n",
        "    - Um AUC de 1 indica um modelo perfeito, que é capaz de fazer todas as previsões corretas.\n",
        "    - Um AUC de 0.5 indica um modelo que faz previsões aleatórias, sem discriminação entre as classes.\n",
        "\n",
        " - Como a AUC é calculada?\n",
        "A AUC é calculada traçando a curva ROC e calculando a área sob essa curva. Aqui estão os passos principais:\n",
        "\n",
        "    - Curva ROC: A curva ROC é construída traçando a Taxa de Verdadeiros Positivos (True Positive Rate, TPR) contra a Taxa de Falsos Positivos (False Positive Rate, FPR) para diferentes valores de threshold de classificação.\n",
        "\n",
        "    - TPR (Sensibilidade): É a proporção de exemplos positivos que são corretamente classificados como positivos.\n",
        "\n",
        "    - FPR: É a proporção de exemplos negativos que são incorretamente classificados como positivos.\n",
        "\n",
        "    - Área sob a curva ROC: A AUC é então calculada como a área sob essa curva ROC. Quanto maior a área sob a curva, melhor é o desempenho do modelo em distinguir entre as classes.\n",
        "\n",
        "  - Quando usar a AUC?\n",
        "A **AUC é especialmente útil quando você tem um conjunto de dados desbalanceado**, ou seja, quando uma classe é muito mais prevalente do que a outra. Nesses casos, a precisão e a acurácia podem não ser métricas adequadas, pois podem ser enganosamente altas apenas devido ao desbalanceamento.\n",
        "\n",
        "Além disso, a **AUC é uma métrica robusta que não é afetada por mudanças na proporção de classes ou na distribuição dos dados.**"
      ],
      "metadata": {
        "id": "ztI27oOml35w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Threshold\" (limiar)** é usado em contextos de classificação para **definir um ponto de corte ou um valor de referência para distinguir entre as classes positiva e negativa.**\n",
        "\n",
        "- Definição: Um threshold **é um valor numérico que define a fronteira entre duas classes em um problema de classificação binária.** Ele determina a decisão de como as previsões do modelo são interpretadas como pertencentes à classe positiva ou à classe negativa.\n",
        "\n",
        "- Aplicação: Em um modelo de classificação binária, após fazer previsões probabilísticas (por exemplo, probabilidade de um exemplo pertencer à classe positiva), você pode aplicar um threshold para converter essas probabilidades em rótulos de classe.\n",
        "\n",
        "- Decisão com Threshold: Para transformar essas probabilidades em rótulos de classe, você aplica um threshold. Por exemplo, se o threshold for 0.5, todas as previsões com probabilidades maiores ou iguais a 0.5 serão rotuladas como classe positiva, e as previsões com probabilidades menores que 0.5 serão rotuladas como classe negativa.\n",
        "\n",
        "- Importância do Threshold:\n",
        "  - Equilíbrio de Precisão e Recall: O threshold permite ajustar o equilíbrio entre precisão e recall do modelo. Por exemplo, um threshold mais baixo pode aumentar o recall (capturando mais exemplos positivos), mas diminuir a precisão (podendo aumentar o número de falsos positivos). Um threshold mais alto pode aumentar a precisão (reduzindo os falsos positivos), mas diminuir o recall (podendo perder alguns exemplos positivos).\n",
        "\n",
        "  - Aplicação Contextual: O threshold deve ser escolhido com base no contexto do problema e nos requisitos específicos de negócio. Por exemplo, em um problema médico de detecção de doenças, pode ser mais importante maximizar o recall, mesmo que isso signifique ter mais falsos positivos.\n",
        "\n",
        "- Como Escolher um Threshold?\n",
        "  - Análise da Curva ROC: A curva ROC mostra a relação entre a taxa de verdadeiros positivos (TPR) e a taxa de falsos positivos (FPR) para diferentes thresholds. Escolher um threshold adequado muitas vezes envolve analisar essa curva e escolher um ponto que atenda aos requisitos do seu problema.\n",
        "\n",
        "  - F1-score ou outras métricas: Além da AUC, métricas como F1-score (que combina precisão e recall) podem ser usadas para ajudar a escolher um threshold.\n",
        "\n",
        "  - Requisitos de Negócio: Em muitos casos, os requisitos específicos do negócio ou da aplicação determinarão qual é o threshold ideal. Por exemplo, se um falso positivo é muito caro em termos de recursos ou impacto, você pode escolher um threshold mais alto para reduzir esses casos."
      ],
      "metadata": {
        "id": "ZnrEVV1-nnAD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7zA5KwzKpDv6"
      }
    }
  ]
}